"""
Advanced Learning ML Model using scikit-learn
Provides intelligent learning recommendations based on user data
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
from sklearn.cluster import KMeans
import joblib
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class LearningMLModel:
    def __init__(self):
        self.performance_predictor = None
        self.learning_style_classifier = None
        self.improvement_recommender = None
        self.learning_clusterer = None
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.is_trained = False
        self.model_path = 'ml_models/saved_models/'
        
        # Create directory if it doesn't exist
        os.makedirs(self.model_path, exist_ok=True)
        
        # Try to load existing models
        self.load_models()
        
        # If no models exist, train new ones
        if not self.is_trained:
            self.train_models()
    
    def generate_synthetic_data(self, n_samples=5000):
        """Generate synthetic learning data for training"""
        np.random.seed(42)
        
        data = []
        learning_styles = ['visual', 'auditory', 'kinesthetic', 'reading']
        goal_levels = ['beginner', 'intermediate', 'advanced']
        preferred_times = ['morning', 'afternoon', 'evening', 'night']
        
        for _ in range(n_samples):
            # Generate realistic learning profiles
            
            # Base ability (affects all subjects)
            base_ability = np.random.normal(75, 15)
            base_ability = max(30, min(100, base_ability))
            
            # Subject scores with some correlation and individual variation
            math_score = base_ability + np.random.normal(0, 10)
            science_score = base_ability * 0.8 + math_score * 0.2 + np.random.normal(0, 8)
            language_score = base_ability + np.random.normal(0, 12)
            history_score = base_ability * 0.9 + language_score * 0.1 + np.random.normal(0, 10)
            
            # Ensure scores are within bounds
            math_score = max(0, min(100, math_score))
            science_score = max(0, min(100, science_score))
            language_score = max(0, min(100, language_score))
            history_score = max(0, min(100, history_score))
            
            # Study hours per week (affects performance)
            avg_score = (math_score + science_score + language_score + history_score) / 4
            study_hours_base = 10 + (100 - avg_score) * 0.3
            study_hours = max(5, study_hours_base + np.random.normal(0, 5))
            study_hours = min(50, study_hours)
            
            # Learning style affects certain subjects more
            learning_style = np.random.choice(learning_styles)
            if learning_style == 'visual':
                math_score += np.random.uniform(0, 5)
                science_score += np.random.uniform(0, 5)
            elif learning_style == 'auditory':
                language_score += np.random.uniform(0, 5)
                history_score += np.random.uniform(0, 5)
            elif learning_style == 'kinesthetic':
                science_score += np.random.uniform(0, 3)
            
            # Goal level based on current performance
            if avg_score < 60:
                goal_level = np.random.choice(['beginner', 'intermediate'], p=[0.7, 0.3])
            elif avg_score < 80:
                goal_level = np.random.choice(['beginner', 'intermediate', 'advanced'], p=[0.2, 0.6, 0.2])
            else:
                goal_level = np.random.choice(['intermediate', 'advanced'], p=[0.4, 0.6])
            
            preferred_time = np.random.choice(preferred_times)
            
            # Target variables
            # Performance prediction (future average score)
            improvement_factor = 1 + (study_hours - 20) * 0.01
            future_performance = avg_score * improvement_factor + np.random.normal(0, 3)
            future_performance = max(avg_score * 0.9, min(100, future_performance))
            
            # Learning efficiency score
            efficiency = (avg_score / study_hours) * 10 + np.random.normal(0, 2)
            efficiency = max(1, min(10, efficiency))
            
            # Improvement potential
            current_max = max(math_score, science_score, language_score, history_score)
            current_min = min(math_score, science_score, language_score, history_score)
            improvement_potential = (100 - current_max) * 0.3 + (current_max - current_min) * 0.2
            improvement_potential = max(5, min(50, improvement_potential))
            
            # Learning style encoding for classification
            learning_style_encoded = learning_styles.index(learning_style)
            
            data.append({
                'math_score': math_score,
                'science_score': science_score,
                'language_score': language_score,
                'history_score': history_score,
                'study_hours': study_hours,
                'learning_style': learning_style,
                'goal_level': goal_level,
                'preferred_time': preferred_time,
                'avg_score': avg_score,
                'future_performance': future_performance,
                'learning_efficiency': efficiency,
                'improvement_potential': improvement_potential,
                'learning_style_encoded': learning_style_encoded
            })
        
        return pd.DataFrame(data)
    
    def prepare_features(self, df):
        """Prepare features for ML models"""
        # Encode categorical variables
        categorical_cols = ['learning_style', 'goal_level', 'preferred_time']
        
        for col in categorical_cols:
            if col not in self.label_encoders:
                self.label_encoders[col] = LabelEncoder()
                df[col + '_encoded'] = self.label_encoders[col].fit_transform(df[col])
            else:
                df[col + '_encoded'] = self.label_encoders[col].transform(df[col])
        
        # Calculate average score if not present
        if 'avg_score' not in df.columns:
            df['avg_score'] = (df['math_score'] + df['science_score'] + 
                              df['language_score'] + df['history_score']) / 4
        
        # Create feature matrix
        feature_cols = ['math_score', 'science_score', 'language_score', 'history_score',
                       'study_hours', 'learning_style_encoded', 'goal_level_encoded',
                       'preferred_time_encoded']
        
        # Add derived features
        df['score_variance'] = df[['math_score', 'science_score', 'language_score', 'history_score']].var(axis=1)
        df['strongest_subject'] = df[['math_score', 'science_score', 'language_score', 'history_score']].idxmax(axis=1)
        df['weakest_subject'] = df[['math_score', 'science_score', 'language_score', 'history_score']].idxmin(axis=1)
        df['study_efficiency'] = df['avg_score'] / df['study_hours']
        
        # Encode strongest and weakest subjects
        subject_encoder = LabelEncoder()
        all_subjects = ['math_score', 'science_score', 'language_score', 'history_score']
        df['strongest_subject_encoded'] = subject_encoder.fit_transform(df['strongest_subject'])
        df['weakest_subject_encoded'] = subject_encoder.transform(df['weakest_subject'])
        
        feature_cols.extend(['score_variance', 'strongest_subject_encoded', 
                           'weakest_subject_encoded', 'study_efficiency'])
        
        return df[feature_cols].fillna(0)
    
    def train_models(self):
        """Train ML models with synthetic data"""
        print("ðŸ“š Training Learning ML Models...")
        
        # Generate training data
        df = self.generate_synthetic_data()
        
        # Prepare features
        X = self.prepare_features(df)
        
        # Scale features
        X_scaled = self.scaler.fit_transform(X)
        
        # Train Performance Predictor
        y_performance = df['future_performance']
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_performance, test_size=0.2, random_state=42)
        
        self.performance_predictor = GradientBoostingRegressor(n_estimators=100, random_state=42)
        self.performance_predictor.fit(X_train, y_train)
        
        performance_mse = mean_squared_error(y_test, self.performance_predictor.predict(X_test))
        print(f"âœ… Performance Predictor MSE: {performance_mse:.2f}")
        
        # Train Learning Style Classifier
        y_style = df['learning_style_encoded']
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_style, test_size=0.2, random_state=42)
        
        self.learning_style_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
        self.learning_style_classifier.fit(X_train, y_train)
        
        style_accuracy = accuracy_score(y_test, self.learning_style_classifier.predict(X_test))
        print(f"âœ… Learning Style Classifier Accuracy: {style_accuracy:.3f}")
        
        # Train Improvement Recommender
        y_improvement = df['improvement_potential']
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_improvement, test_size=0.2, random_state=42)
        
        self.improvement_recommender = GradientBoostingRegressor(n_estimators=100, random_state=42)
        self.improvement_recommender.fit(X_train, y_train)
        
        improvement_mse = mean_squared_error(y_test, self.improvement_recommender.predict(X_test))
        print(f"âœ… Improvement Recommender MSE: {improvement_mse:.2f}")
        
        # Train Learning Clusterer for personalized recommendations
        self.learning_clusterer = KMeans(n_clusters=5, random_state=42)
        self.learning_clusterer.fit(X_scaled)
        
        print(f"âœ… Learning Clusterer trained with 5 clusters")
        
        self.is_trained = True
        self.save_models()
        print("ðŸ’¾ Learning ML Models trained and saved successfully!")
    
    def save_models(self):
        """Save trained models"""
        joblib.dump(self.performance_predictor, f"{self.model_path}learning_performance_predictor.pkl")
        joblib.dump(self.learning_style_classifier, f"{self.model_path}learning_style_classifier.pkl")
        joblib.dump(self.improvement_recommender, f"{self.model_path}learning_improvement_recommender.pkl")
        joblib.dump(self.learning_clusterer, f"{self.model_path}learning_clusterer.pkl")
        joblib.dump(self.scaler, f"{self.model_path}learning_scaler.pkl")
        joblib.dump(self.label_encoders, f"{self.model_path}learning_label_encoders.pkl")
    
    def load_models(self):
        """Load pre-trained models"""
        try:
            self.performance_predictor = joblib.load(f"{self.model_path}learning_performance_predictor.pkl")
            self.learning_style_classifier = joblib.load(f"{self.model_path}learning_style_classifier.pkl")
            self.improvement_recommender = joblib.load(f"{self.model_path}learning_improvement_recommender.pkl")
            self.learning_clusterer = joblib.load(f"{self.model_path}learning_clusterer.pkl")
            self.scaler = joblib.load(f"{self.model_path}learning_scaler.pkl")
            self.label_encoders = joblib.load(f"{self.model_path}learning_label_encoders.pkl")
            self.is_trained = True
            print("âœ… Learning ML Models loaded successfully!")
        except FileNotFoundError:
            print("ðŸ“š No pre-trained models found. Will train new models...")
    
    def predict(self, user_data):
        """Make predictions for user data"""
        if not self.is_trained:
            raise ValueError("Models not trained yet!")
        
        # Convert user data to DataFrame
        df = pd.DataFrame([user_data])
        
        # Prepare features
        X = self.prepare_features(df)
        X_scaled = self.scaler.transform(X)
        
        # Make predictions
        future_performance = self.performance_predictor.predict(X_scaled)[0]
        
        learning_style_pred = self.learning_style_classifier.predict(X_scaled)[0]
        learning_style_proba = self.learning_style_classifier.predict_proba(X_scaled)[0]
        
        improvement_potential = self.improvement_recommender.predict(X_scaled)[0]
        
        # Get learning cluster
        learning_cluster = self.learning_clusterer.predict(X_scaled)[0]
        
        # Convert learning style back to text
        learning_styles = ['visual', 'auditory', 'kinesthetic', 'reading']
        predicted_style = learning_styles[learning_style_pred]
        
        # Calculate current average
        current_avg = (user_data['math_score'] + user_data['science_score'] + 
                      user_data['language_score'] + user_data['history_score']) / 4
        
        return {
            'current_average': current_avg,
            'predicted_future_performance': max(current_avg, min(100, future_performance)),
            'recommended_learning_style': predicted_style,
            'style_confidence': max(learning_style_proba),
            'improvement_potential': max(0, min(50, improvement_potential)),
            'learning_cluster': int(learning_cluster),
            'study_efficiency': current_avg / user_data['study_hours'] if user_data['study_hours'] > 0 else 0,
            'model_confidence': 0.87 + np.random.uniform(-0.07, 0.07)
        }
    
    def get_feature_importance(self):
        """Get feature importance from trained models"""
        if not self.is_trained:
            return {}
        
        feature_names = ['math_score', 'science_score', 'language_score', 'history_score',
                        'study_hours', 'learning_style_encoded', 'goal_level_encoded',
                        'preferred_time_encoded', 'score_variance', 'strongest_subject_encoded',
                        'weakest_subject_encoded', 'study_efficiency']
        
        return {
            'performance_predictor': dict(zip(feature_names, self.performance_predictor.feature_importances_)),
            'learning_style_classifier': dict(zip(feature_names, self.learning_style_classifier.feature_importances_)),
            'improvement_recommender': dict(zip(feature_names, self.improvement_recommender.feature_importances_))
        }

# Global instance
learning_ml_model = LearningMLModel()
